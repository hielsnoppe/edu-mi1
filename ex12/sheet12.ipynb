{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 12.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+----------+\n",
      "| Node       | Value | Marginal |\n",
      "+------------+-------+----------+\n",
      "| alarm      | False | 0.989506 |\n",
      "| alarm      | True  | 0.010494 |\n",
      "| burglary   | False | 0.990000 |\n",
      "| burglary   | True  | 0.010000 |\n",
      "| earthquake | False | 0.999990 |\n",
      "| earthquake | True  | 0.000010 |\n",
      "| radio      | False | 0.999990 |\n",
      "| radio      | True  | 0.000010 |\n",
      "+------------+-------+----------+\n",
      "+------------+-------+----------+\n",
      "| Node       | Value | Marginal |\n",
      "+------------+-------+----------+\n",
      "| alarm      | False | 0.000000 |\n",
      "| alarm*     | \u001b[92mTrue*\u001b[0m | 1.000000 |\n",
      "| burglary   | False | 0.976425 |\n",
      "| burglary   | True  | 0.023575 |\n",
      "| earthquake | False | 0.000000 |\n",
      "| earthquake | True  | 1.000000 |\n",
      "| radio      | False | 0.000000 |\n",
      "| radio*     | \u001b[92mTrue*\u001b[0m | 1.000000 |\n",
      "+------------+-------+----------+\n",
      "+------------+-------+----------+\n",
      "| Node       | Value | Marginal |\n",
      "+------------+-------+----------+\n",
      "| alarm      | False | 0.000000 |\n",
      "| alarm*     | \u001b[92mTrue*\u001b[0m | 1.000000 |\n",
      "| burglary   | False | 0.094725 |\n",
      "| burglary   | True  | 0.905275 |\n",
      "| earthquake | False | 0.999604 |\n",
      "| earthquake | True  | 0.000396 |\n",
      "| radio      | False | 0.999604 |\n",
      "| radio      | True  | 0.000396 |\n",
      "+------------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "from bayesian.bbn import build_bbn\n",
    "from bayesian.utils import make_key\n",
    "\n",
    "def f_burglary(burglary):\n",
    "    if burglary:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return 0.99\n",
    "\n",
    "def f_earthquake(earthquake):\n",
    "    if earthquake:\n",
    "        return 10e-6\n",
    "    else:\n",
    "        return 1.-10e-6\n",
    "\n",
    "def f_alarm(burglary, earthquake, alarm):\n",
    "    table = dict()\n",
    "    table['fff'] = 0.999\n",
    "    table['fft'] = 0.001\n",
    "    table['ftf'] = 0.59\n",
    "    table['ftt'] = 0.41\n",
    "    table['tff'] = 0.05\n",
    "    table['tft'] = 0.95\n",
    "    table['ttf'] = 0.02\n",
    "    table['ttt'] = 0.98\n",
    "    return table[make_key(burglary, earthquake, alarm)]\n",
    "\n",
    "def f_radio(earthquake, radio):\n",
    "    table = dict()\n",
    "    table['ff'] = 1.0\n",
    "    table['ft'] = 0.0\n",
    "    table['tf'] = 0.0\n",
    "    table['tt'] = 1.0\n",
    "    return table[make_key(earthquake, radio)]\n",
    "\n",
    "\n",
    "g = build_bbn(\n",
    "    f_burglary,\n",
    "    f_earthquake,\n",
    "    f_alarm,\n",
    "    f_radio)\n",
    "g.q()\n",
    "g.q(alarm=1,radio=1)\n",
    "g.q(alarm=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p(B=t|A=t,R=t):  | burglary   | True  | 0.023575 |\n",
    "p(B=t|A=t):      | burglary   | True  | 0.905275 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def p(b=[0,1],e=[0,1],a=[0,1],r=[0,1]):\n",
    "    if isinstance(b, int): b = [b]\n",
    "    if isinstance(e, int): e = [e]\n",
    "    if isinstance(a, int): a = [a]\n",
    "    if isinstance(r, int): r = [r]\n",
    "   \n",
    "    # variable syntax: p_...x := p(x|...)\n",
    "    p_b = [0.99, 0.01]\n",
    "    p_e = [1.-10e-6, 10e-6]\n",
    "    p_er = [[1.0, 0.0], [0.0, 1.0]]\n",
    "    p_bea = [[[0.999, 0.001], [0.59, 0.41]], [[0.05, 0.95], [0.02, 0.98]]]\n",
    " \n",
    "    p_sum = 0.0\n",
    "    for bi in b:\n",
    "        for ei in e:\n",
    "            for ai in a:\n",
    "                for ri in r:\n",
    "                    p_sum += p_b[bi] * p_e[ei] * p_er[ei][ri] * p_bea[bi][ei][ai]\n",
    "\n",
    "    return p_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(B=1|A=1,R=1) =  0.0235746932884\n",
      "p(B=1|A=1) =      0.905274998587\n"
     ]
    }
   ],
   "source": [
    "pb_ar = p(b=1,a=1,r=1) / p(a=1,r=1)\n",
    "pb_a = p(b=1,a=1) / p(a=1)\n",
    "print \"p(B=1|A=1,R=1) = \", pb_ar\n",
    "print \"p(B=1|A=1) =     \", pb_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"12-1-ab.jpg\" />\n",
    "<img src=\"12-1-b-rest.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define potentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(b=[0,1],e=[0,1],a=[0,1]):\n",
    "    if isinstance(b, int): b = [b]\n",
    "    if isinstance(e, int): e = [e]\n",
    "    if isinstance(a, int): a = [a]\n",
    "   \n",
    "    # variable syntax: p_...x := p(x|...)\n",
    "    p_b = [0.99, 0.01]\n",
    "    p_e = [1.-10e-6, 10e-6]\n",
    "    p_bea = [[[0.999, 0.001], [0.59, 0.41]], [[0.05, 0.95], [0.02, 0.98]]]\n",
    " \n",
    "    p_sum = 0.0\n",
    "    for bi in b:\n",
    "        for ei in e:\n",
    "            for ai in a:\n",
    "                p_sum += p_b[bi] * p_e[ei] * p_bea[bi][ei][ai]\n",
    "\n",
    "    return p_sum\n",
    "\n",
    "def g(e=[0,1],r=[0,1]):\n",
    "    if isinstance(e, int): e = [e]\n",
    "    if isinstance(r, int): r = [r]\n",
    "   \n",
    "    # variable syntax: p_...x := p(x|...)\n",
    "    p_e = [1.-10e-6, 10e-6]\n",
    "    p_er = [[1.0, 0.0], [0.0, 1.0]]\n",
    "    \n",
    "    p_sum = 0.0\n",
    "    for ei in e:\n",
    "        for ri in r:\n",
    "            p_sum += p_e[ei] * p_er[ei][ri]\n",
    "\n",
    "    return p_sum\n",
    "\n",
    "def h(e):\n",
    "    if isinstance(e, int): e = [e]\n",
    "   \n",
    "    p_e = [1.-10e-6, 10e-6]\n",
    " \n",
    "    p_sum = 0.0\n",
    "    for ei in e:\n",
    "        p_sum += p_e[ei]\n",
    "\n",
    "    return p_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "introduce evidence by indicator functions (here: identity-functions `E(ai)=ai`, `E(ri)=ri`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_(b=[0,1],e=[0,1],a=[0,1]):\n",
    "    if isinstance(b, int): b = [b]\n",
    "    if isinstance(e, int): e = [e]\n",
    "    if isinstance(a, int): a = [a]\n",
    "   \n",
    "    p_sum = 0.0\n",
    "    for bi in b:\n",
    "        for ei in e:\n",
    "            for ai in a:\n",
    "                p_sum += f(b=bi,e=ei,a=ai) * ai\n",
    "\n",
    "    return p_sum\n",
    "\n",
    "def g_(e=[0,1],r=[0,1]):\n",
    "    if isinstance(e, int): e = [e]\n",
    "    if isinstance(r, int): r = [r]\n",
    "   \n",
    "    p_sum = 0.0\n",
    "    for ei in e:\n",
    "        for ri in r:\n",
    "            p_sum += g(e=ei,r=ri) * ri\n",
    "\n",
    "    return p_sum\n",
    "\n",
    "def h_(e=[0,1]): return h(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "P(b=1|a=1)\n",
      "0.905274998587\n",
      "0.905274998587\n"
     ]
    }
   ],
   "source": [
    "print \"\\nP(b=1|a=1)\"\n",
    "print f(b=1,a=1)/f(a=1)  # original function\n",
    "print f_(b=1)/f_(a=1)  # with indicator function (already incorporates evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation with functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test1: computing conditional marginals\n",
      "e p(..b=0..) p(..b=1..)\n",
      "0 0.00000000 0.00000000\n",
      "1 0.97642531 0.02357469\n",
      "\n",
      "test1: computing conditional marginals\n",
      "e p(..b=0..) p(..b=1..)\n",
      "0 0.00000000 0.00000000\n",
      "1 0.97642531 0.02357469\n",
      "[0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# junction tree:\n",
    "# (bea) -- [e] -- (er)\n",
    "#   f       h      g\n",
    "\n",
    "def test_be(f,g):\n",
    "    print \"\\ntest1: computing conditional marginals\"\n",
    "    T = np.zeros((2,2))\n",
    "    for e in [0,1]:\n",
    "        for b in [0,1]:\n",
    "            T[e,b] = f(b=b,e=e) * g(e=e) / h(e=e)\n",
    "    \n",
    "    # normalize!\n",
    "    T = T/T.sum()\n",
    "\n",
    "    print(\"e p(..b=0..) p(..b=1..)\")\n",
    "    for e in [0,1]:\n",
    "        print(\"%i %.8f %.8f\" % (e, T[e,0], T[e,1]))\n",
    "    return\n",
    "\n",
    "def test_bea(f,g):\n",
    "    print \"\\ntest1: computing conditional marginals\"\n",
    "    T = np.zeros((2,2,2))\n",
    "    for e in [0,1]:\n",
    "        for a in [0,1]:\n",
    "            for b in [0,1]:\n",
    "                T[e,a,b] = f(b=b,e=e,a=a) * g(e=e) / h(e=e)\n",
    "    \n",
    "    # normalize!\n",
    "    T = T/T.sum()\n",
    "\n",
    "    print(\"ea p(..b=0..) p(..b=1..)\")\n",
    "    for e in [0,1]:\n",
    "        for a in [0,1]:\n",
    "            print(\"%i%i %.8f %.8f\" % (e,a, T[e,a,0], T[e,a,1]))\n",
    "    return\n",
    "\n",
    "\n",
    "# message1 <--\n",
    "h1 = lambda e: g_(e,1)  # no sum, cause r=1 is observed\n",
    "f1 = lambda b,e: f_(b,e,1) * h1(e) / h_(e)\n",
    "test_be(f1,g)\n",
    "\n",
    "# message2 -->\n",
    "h2 = lambda e: sum([f1(b,e) for b in [0,1]])\n",
    "# returns 0 if e==0 to avoid division-by-zero error.\n",
    "# this is valid, because g_(0,anything) == h2(0) == 0.0  (of course one true 0 in a product would suffice)\n",
    "g2 = lambda e: 0.0 if not e else h2(e)/h1(e) * g_(e,1)\n",
    "test_be(f1,g2)\n",
    "\n",
    "print [g_(e,0) for e in S]\n",
    "\n",
    "# separator is now h2 (don't do this, your pc will crash)\n",
    "# h_ = h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation with tables (better):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "h1(e) = g(e,r=1)\n",
      "[0.0, 1e-05]\n",
      "\n",
      "f1(b,e=1,a) = h1(e=1)/h_(e=1) * f_(b,e=1,a)\n",
      "[[0.0, 0.0], [4.059e-06, 9.8e-08]]\n",
      "\n",
      "h2(e) = h1(e)/h_(e) * sum_b[ f(b,e,a=1) ]\n",
      "[0.0, 4.156999999999999e-06]\n",
      "\n",
      "g2(e=1,r) = h2(e)/h1(e) * g_(e,r)\n",
      "[[0.0], [4.156999999999999e-06]]\n",
      "\n",
      "P(B=1|A=1,R=1)\n",
      "0.0235746932884\n",
      "\n",
      "P(B=1|A=1)\n",
      "0.905274998587\n"
     ]
    }
   ],
   "source": [
    "S = [0,1]\n",
    "\n",
    "print \"\\nh1(e) = g(e,r=1)\"\n",
    "H1 = [g(e,r=1) for e in S]\n",
    "print H1\n",
    "\n",
    "print \"\\nf1(b,e=1,a) = h1(e=1)/h_(e=1) * f_(b,e=1,a)\"\n",
    "# like in the cell above, skip e==0 to avoid division by zero (the result would have been 0 anyway)\n",
    "F1 = [[h1(e)/h_(e) * f_(b,e,a) for b in S] for e in [1] for a in S]\n",
    "print F1\n",
    "\n",
    "print \"\\nh2(e) = h1(e)/h_(e) * sum_b[ f(b,e,a=1) ]\"\n",
    "H2 = [(h1(e)/h_(e))*sum([f(b,e,1) for b in S]) for e in S]\n",
    "print H2\n",
    "\n",
    "print \"\\ng2(e=1,r) = h2(e)/h1(e) * g_(e,r)\"\n",
    "# like in the cell above, skip e==0 to avoid division by zero (the result would have been 0 anyway)\n",
    "G2 = [[(h2(e)/h1(e)) * g_(e,r) for e in [1]] for r in S]\n",
    "print G2\n",
    "\n",
    "\n",
    "def prob():\n",
    "    T = np.zeros(2)\n",
    "    r = 1\n",
    "    a = 1\n",
    "    e = 1  # we haven't observed this, but we can still set this to 1, since T[b] is 0 otherwise (since r=1 <=> e=1)\n",
    "    for b in [0,1]:\n",
    "#         T[b] = F1[a][b] * G2[r][0] / H2[e]\n",
    "        T[b] = F1[a][b] * G2[r][0]\n",
    "    T = T/T.sum()\n",
    "    return T\n",
    "\n",
    "print \"\\nP(B=1|A=1,R=1)\"\n",
    "print prob()[1]\n",
    "\n",
    "print \"\\nP(B=1|A=1)\"\n",
    "print p(b=1,a=1) / p(a=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p(B=t|A=t,R=t):  | burglary   | True  | 0.023575 |\n",
    "p(B=t|A=t):      | burglary   | True  | 0.905275 |\n",
    "\n",
    "correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Effect of R=1\n",
    "Since radio and earthquake are tied so strongly, hearing about it on the radio makes the earthquake much more likely to be the cause of the alarm.\n",
    "\n",
    "Mathematically, A and R are conditionally independent given E:\n",
    "    \n",
    "    P(A|E) = P(A|E,R)\n",
    "\n",
    "(having observed E, additionally observing R gives us nothing)\n",
    "\n",
    "Since we haven't observed E though, A and R **are dependent**:\n",
    "\n",
    "    P(A) != P(A|R)\n",
    "    \n",
    "This in turn influences the probability that a burglary caused the alarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9895059479, 0.0104940521]    p(a) ,      a in [0,1]\n",
      "[0.5843, 0.41569999999999996]   p(a|r=1) ,  a in [0,1]\n"
     ]
    }
   ],
   "source": [
    "print [p(a=a) for a in S], \"   p(a) ,      a in [0,1]\"\n",
    "print [p(a=a,r=1) / p(r=1) for a in S], \"  p(a|r=1) ,  a in [0,1]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (all the important stuff is above, only experiments past here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ear p(..b=0..) p(..b=1..)\n",
      "000 0.00000000 0.00000000\n",
      "001 0.00000000 0.00000000\n",
      "010 0.00000000 0.00000000\n",
      "011 0.00000000 0.00000000\n",
      "100 0.00000000 0.00000000\n",
      "101 0.00000000 0.00000000\n",
      "110 0.00000000 0.00000000\n",
      "111 0.97642531 0.02357469\n",
      "[ 0.99894848  0.00105152]\n"
     ]
    }
   ],
   "source": [
    "# you can use the modified functions to compute the conditionial marginals\n",
    "def test_bear(f,g):\n",
    "    T = np.zeros((2,2,2,2))\n",
    "    for e in [0,1]:\n",
    "        for a in [0,1]:\n",
    "            for r in [0,1]:\n",
    "                for b in [0,1]:\n",
    "                    T[e,a,r,b] = f(b=b,e=e,a=a) * g(e=e,r=r)\n",
    "    \n",
    "    # normalize!\n",
    "    T = T/T.sum()\n",
    "\n",
    "    print(\"ear p(..b=0..) p(..b=1..)\")\n",
    "    for e in [0,1]:\n",
    "        for a in [0,1]:\n",
    "            for r in [0,1]:\n",
    "                print(\"%i%i%i %.8f %.8f\" % (e,a,r, T[e,a,r,0], T[e,a,r,1]))\n",
    "    return\n",
    "test_bear(f_,g_)\n",
    "\n",
    "# but you can't separate the product in a sum if both factors depend on the same variable (e)\n",
    "def test_sum():\n",
    "    fsum = sum([f_(b=1,e=e,a=1) for e in [0,1]])\n",
    "    gsum = sum([g_(e=e,r=1) for e in [0,1]])\n",
    "    \n",
    "    T = np.array([fsum, gsum])\n",
    "    T = T/T.sum()\n",
    "    print T\n",
    "    return\n",
    "test_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 12.2\n",
    "\n",
    "## a)\n",
    "- Bayesian learning belongs to the class of generative models (opposite: discriminative models), where the output prediction $ P(y \\mid x) $ is calculated from the marginal pdf $ P(x\\mid y) $ and the conditional pdf $ P(x\\mid y) $ by applying Bayes' rule\n",
    "- For Bayesian learning, the inputs $x^{(1)},...,x^{(n)}$ are used to find reasonable model parameters $\\theta$. Before using training data to perform the learning algorithm, a prior distribution $P(\\theta)$ needs to be defined, by using initial beliefs about the model parameters. When working with MLPs, the model parameters are represented by the weights and biases of the single perceptrons.\n",
    "- To capture the impact of observations on the model parameters, a likelihood function is introduced: \n",
    "$$ L( \\theta)=L( \\theta \\mid x^{(1)},...,x^{(n)}) \\propto P(x^{(1)},...,x^{(n)}\\mid \\theta) $$\n",
    "- Since the log of the likelihood function is proportional to the squared error sum, using this error measure will make training an MLP equivalent to maximum likelihood estimation for the gaussian noise model.\n",
    "- After the observation of the input, the pdf $P(\\theta \\mid x^{(1)},...,x^{(n)})$ will be updated, now called posterior function by using \n",
    "- The predictive distribution is the Bayesian inference and allows us to predict the value of an unknown input $x^{(n+1)}$ given privious inputs by eleminating the model parameters of known distributions: $$ P(x^{(n+1)}\\mid x^{(1)},...,x^{(n)}) \\;=\\; \\int P(x^{(n+1)}\\mid \\theta) P( \\theta \\mid x^{(1)},...,x^{(n)}) d \\theta $$\n",
    "\n",
    "\n",
    "\n",
    "## b)\n",
    "- The concept, that model complexity should be limited to avoid an overfitted model doesn't apply to Bayesian learning in a strong matter. This leads to the rule that complexity should only be limited by computational restrictions.\n",
    "- Bayesian learning is not a method to find scientific explanations or estimate real parameter (nonparametric, since used parameters like weights have no physical meaning for the problem itself) and it's complexity can not simply be defined by the amount of parameters what makes it very different from other approaches.\n",
    "- When training the model, the weight decay must be well adjusted to avoid both overfitting and underfitting. This is difficult because there is no obvious relationship between the weights and the actual problem.\n",
    "- Underfitting / overfitting is difficult to control, caused by several reasons. For example the prior distribution needs to be choosen arbitrary and in many cases, choosing them by random delivers resonable results. The same applies to the weight penalty. These problems can partially be reduced by using cross validation. It's also common to work with rules of thumb.\n",
    "- MLPs are hierarchical what gives them one more degree of freedom and makes them more flexible. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## c)\n",
    "\n",
    "- SRM is a deterministic approach for finding a model with a good balance between complexity and the success on test data. Models of the same function class but with different complexities ( possibly represented by VC-dimension or the degree of used functions) are sortet according to their complexity, which might cause overfitting when too large and the empirical (training) error, which tends towards zero for overfitted models. \n",
    "- Each model class is tested for the best parameter set (empirical risk minimisation) in order to find the best compromise of empirical error and complexity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
