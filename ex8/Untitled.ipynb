{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.35294118  0.          3.35294118]\n",
      "[-10.73684211  -0.          10.73684211]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "\n",
    "w0 = np.linspace(-1,1,20)\n",
    "w1 = np.linspace(1,-1,20)\n",
    "b = np.linspace(0,3,10)\n",
    "\n",
    "x1 = np.linspace(-6,6,3)\n",
    "x2 = np.linspace(-6,6,3)\n",
    "\n",
    "def classify(w0,w1,b,x1,x2):\n",
    "    x01 = np.divide(-1.0*(np.dot(w1,x2)+b),(w0))\n",
    "    x02 = np.divide(-1.0*(np.dot(w0,x1)+b),(w1))\n",
    "    return x01, x02\n",
    "\n",
    "# w0 in [-1,1], w1 in {0.5,1}, b = 0\n",
    "plt.figure(figsize=(6,6))\n",
    "for i in range(len(w0)):\n",
    "    x01t, x02t = classify(w0[i],0.5,0,x1,x2)\n",
    "    plt.plot(x01t,x02t,color = 'g',label='w005',linewidth=(0.5+2*i/len(w1)))\n",
    "    if i==1:\n",
    "        print(x01t)\n",
    "        print(x02t)\n",
    "    x01t, x02t = classify(w0[i],1,0,x1,x2)\n",
    "    plt.plot(x01t,x02t,color = 'r',label='w01',linewidth=(0.5+2*i/len(w1)))\n",
    "plt.grid()\n",
    "plt.xlim((-6,6))\n",
    "plt.ylim((-6,6))\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "plt.legend(['$w_1=0.5$','$w_1=1$'])\n",
    "plt.title('$w_0 \\in [-1,1], w_1 \\in \\{0.5,1\\}, b = 0$')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# w0 in {-1,1}, w1 in [-1,1], b = 1\n",
    "plt.figure(figsize=(6,6))\n",
    "for i in range(len(w0)):\n",
    "    x01t, x02t = classify(-1,w1[i],1,x1,x2)\n",
    "    plt.plot(x01t,x02t,color = 'g',label='w1neg',linewidth=(0.5+2*i/len(w1)))\n",
    "    x01t, x02t = classify(1,w1[i],1,x1,x2)\n",
    "    plt.plot(x01t,x02t,color = 'r',label='w1pos',linewidth=(0.5+2*i/len(w1)))\n",
    "plt.grid()\n",
    "plt.xlim((-6,6))\n",
    "plt.ylim((-6,6))\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "plt.legend(['$w_0=-1$','$w_0=1$'])\n",
    "plt.title('$w_0 \\in \\{-1,1\\}, w_1 \\in [-1,1], b = 0$')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# w0 = 0.5, w1 = 1, b in [0,3]\n",
    "plt.figure(figsize=(6,6))\n",
    "for i in range(len(b)):\n",
    "    x01t, x02t = classify(0.5,2,b[i],x1,x2)\n",
    "    plt.plot(x01t,x02t,color = 'g',linewidth=(0.5+2*i/len(b)),label='w11')\n",
    "    x01t, x02t = classify(1,2,b[i],x1,x2)\n",
    "    plt.plot(x01t,x02t,color = 'r',linewidth=(0.5+2*i/len(b)),label='w01')\n",
    "plt.grid()\n",
    "plt.xlim((-6,6))\n",
    "plt.ylim((-6,6))\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "plt.legend(['$w_0=0.5$','$w_0=1$'])\n",
    "plt.title('$w_0 \\in \\{0.5,1\\}, w_1 = 2, b \\in [0,3]$')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- the decision boundary is given by $\\{x\\;|\\;y=0\\}$\n",
    "- this can be expressed as a linear function: $x_1 = \\;-\\frac{w_0}{w_1}x_0 \\;-\\; \\frac{b}{w_1}$\n",
    "- as one can see, the slope of the boundary is $\\;-\\frac{w_0}{w_1}$ and the offset is $\\;-\\frac{b}{w_1}$\n",
    "    - figure 1: $w_0$ only affects the slope\n",
    "    - figure 2: varying $w_1$ also results in different offsets\n",
    "    - figure 3: increasing $b$ leads to a negative offset, scaled by $w_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shattering Coefficient:\n",
    "\n",
    "- the n'th shattering coefficient of a set of classification functions gives the largest number of different             subsets in which a set of $n$ data points can be divided\n",
    "- the highest possible shattering coefficient is $2^{n}$\n",
    "\n",
    "VC Dimension:\n",
    "\n",
    "- the VC dimension of a set of classification functions gives the maximum number of training points which can be classified correctly for all possible output labelings of these training points\n",
    "- for a linear classifier in 2 dimensions, the VC-dimension is 2\n",
    "\n",
    "\n",
    "\n",
    "- correct linear classification is possible, if all classes can be bounded by non-overlapping convex domains\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
